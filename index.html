<!doctype html>
<html>
  <head>
    <script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>NeuroPhi by Markus Woodson and Danielle Rager</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/mwoodson1/15418FinalProject">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/mwoodson1/15418FinalProject/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/mwoodson1/15418FinalProject/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
          <h1>NeuroPhi</h1>
          <p></p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/mwoodson1">mwoodson1</a>,<a href="https://github.com/dmrager">dmrager</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </div>

        <h3>

<a href="proposal.html">Proposal</a>
<a href="checkpoint.html">Checkpoint</a>

<h3>Summary</h3>
<p>Neurophi is a C++ framework with a MATLAB interface for doing fast, parallel convolutional neural network (CNN) training, particularly for large image sizes. Unlike the existing parallel CNN training frameworks that rely on CUDA and GPU computation, NeuroPhi's target hardware is a CPU and Intel Xeon Phi Coprocessor. NeuroPhi therefore supports code written for standard x86 architecture and can be extended using standard C++ parallelization tools including OpenMP, Cilk, and ISPC. NeuroPhi also differentiates itself from existing parallel CNN training frameworks by computing convolutions in the Fourier domain, which is optimal for large images and kernels, and by parallelizing mini-batch training of the network across cores. </p>
<p></p>

<h3>Background</h3>
<p>Artificial neural networks (ANNs) are a biologically-inspired machine learning method of solving classes of problems that require learning. Given a class of simple functions <i>F</i> and a set of observations <i>O</i>, an ANN will learn the transfer functions for each node or neuron in one or more hidden layers of a network such that the network optimally solves a specified problem. The ability to learn using a hierarchy of simple transfer functions has made ANNs key computational models for applications such as computer vision and speech recognition. However, large neural networks--which may have several hidden layers, thousands to millions of nodes per layer, and thousands to millions of edges between layers--are very computationally expensive to train.

A common supervised ANN training algorithm known as backpropagation iteratively updates the weights of the network to minimize a loss function--the difference between a known, desired network output and the current network output--by determining the contribution of each input weight and bias in the network to the loss function. The basic steps of backpropagation are as follows</p>

<ul>
  <li>Initialize the input layer of the network to include an input for bias</li>
  <li>Propagate the activity forward for each layer of the network</li>
  <li>Calculate the error at the output layer</li>
  <li>Back-propagate the error through the other network layers</li>
  <li>Update the weights of the network</li>
</ul>

<p>
A convolutional neural network is similar to a classic ANN but allows for different types of layers in the network. Some of the key layers are outlines below:
</p>

<b>Convolutional layer</b>
<p>
  This layers input parameters are a set of learnable filters. Each one of these filters is then convolved with the input volume to produce its output. The process of convolution can be expressed by the following formula in 1D
</br>
  <img src="1dConvolution.jpg">
</br>
  In 2D this can be visualized as the following:
</br>
  <img src="kernel_convolution.jpg">
</br>
  The following is a naive implementation of 2D convolution:
  <pre><code>for w in 1..W
  for h in 1..H
    for x in 1..K
      for y in 1..K
        output(w, h) += input(w+x, h+y) * filter(x, y)
      end
    end
  end
end
</code></pre>
  Most CNN libraries use clever tricks to manipulate the matrices involved in the convolution and take advantage of fast matrix multiplication with cblas. In particular one can "stack" the filters on top of one another and do 1 large convolution instead of several smaller ones. More on this can be read -----ADD LINK HERE TO CAFFE CONV IMP-------
</p>

</br>
<b>Pooling layer</b>
<p>
  In order to reduce output variance, pooling layers simply take the max or average value of a feature over a region of the image. This ensures that the network will have the same output for small translations of the input image.
</p>

</br>
<b>Fully connected</b>
<p>
This is a classic ANN layer and can be visualized below:
</p>
</br>
<img src="fully_connected.png">
<p>
</p>

<p>
CNN's have had great success in image classification and face recognition tasks but most, if not all, of the implementations used GPU implementations for speed. 
</p>

<h3>Approach</h3>
We decided to optimize the convolutional layer and implement parallel mini-batch training to speed up training. NeuroPhi's convolutional layer uses Fast Fourier Transforms, which transform the convolution operator into a simple element-wise product of the FFT of the image and FFT of the kernel. We also have begun parallelizing batch-training by having every core concurrently train on an independent batch of images. The results of the parallel batch-training are then reduced across cores and the network weights are updated accordingly.



  </body>
</html>
